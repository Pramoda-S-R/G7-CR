{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import xgboost as xgb\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import LSTM, Dense # type: ignore\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = \"Emissions_Totals_E_All_Data.csv\"\n",
    "df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ruptures as rpt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from scipy.signal import periodogram\n",
    "import numpy as np\n",
    "\n",
    "def detect_seasonality_period(data: pd.Series) -> int:\n",
    "    \"\"\"\n",
    "    Detect dominant seasonality period in a time series using periodogram.\n",
    "    If no clear peak is found, return 1 (no seasonality).\n",
    "    \"\"\"\n",
    "    freqs, psd = periodogram(data.dropna())\n",
    "    if len(freqs) == 0 or len(psd) == 0:\n",
    "        return 1\n",
    "    \n",
    "    dominant_freq = freqs[np.argmax(psd[1:]) + 1]  # Ignore the first zero frequency\n",
    "    if dominant_freq == 0:\n",
    "        return 1\n",
    "    period = int(round(1 / dominant_freq))\n",
    "    return max(period, 1)\n",
    "\n",
    "def analyze_timeseries(data: pd.Series, title: str = 'Time Series Analysis'):\n",
    "    \"\"\"\n",
    "    Visualize trends, seasonality, and change points in a time series.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.Series): Time series data (index = Years, values = Emissions).\n",
    "    - title (str): Title prefix for plots.\n",
    "    \"\"\"\n",
    "    # Detect period\n",
    "    detected_period = detect_seasonality_period(data)\n",
    "    \n",
    "    # Decompose the series\n",
    "    decomposition = seasonal_decompose(data, model='additive', period=detected_period, extrapolate_trend='freq')\n",
    "    trend = decomposition.trend\n",
    "\n",
    "    # Setup figure\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(16, 14))\n",
    "    \n",
    "    # 1. Original Series\n",
    "    sns.lineplot(x=data.index, y=data.values, marker='o', ax=axs[0])\n",
    "    axs[0].set_title(f'{title} - Original Data')\n",
    "    axs[0].set_xlabel('Year')\n",
    "    axs[0].set_ylabel('Emissions')\n",
    "    \n",
    "    # 2. Trend Component\n",
    "    sns.lineplot(x=trend.index, y=trend.values, color='green', ax=axs[1])\n",
    "    axs[1].set_title(f'{title} - Trend Component')\n",
    "    axs[1].set_xlabel('Year')\n",
    "    axs[1].set_ylabel('Trend')\n",
    "    \n",
    "    # 3. Change Point Detection\n",
    "    algo = rpt.Pelt(model=\"l2\").fit(data.values)\n",
    "    result = algo.predict(pen=2)\n",
    "\n",
    "    sns.lineplot(x=data.index, y=data.values, marker='o', ax=axs[2])\n",
    "    for i, cp in enumerate(result[:-1]):  # Skip the last (end point)\n",
    "        axs[2].axvline(x=data.index[cp], color='red', linestyle='--', label='Change Point' if i == 0 else \"\")\n",
    "    axs[2].set_title(f'{title} - Change Points')\n",
    "    axs[2].set_xlabel('Year')\n",
    "    axs[2].set_ylabel('Emissions')\n",
    "    axs[2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_emissions_data(df: pd.DataFrame, areas: list[str], items: list[int], elements: list[str]) -> pd.DataFrame:\n",
    "    # Filter dataset\n",
    "    df_filtered = df[\n",
    "        (df[\"Area\"].isin(areas)) &\n",
    "        (df[\"Item Code\"].isin(items)) &\n",
    "        (df[\"Element\"].isin(elements)) &\n",
    "        (df[\"Unit\"] == \"kt\")  # Ensure emissions are in kilotonnes\n",
    "    ]\n",
    "    \n",
    "    # Reshape dataset to time series format\n",
    "    year_columns = [col for col in df_filtered.columns if col.startswith(\"Y\") and col[1:].isdigit()]\n",
    "    df_ts = df_filtered.melt(id_vars=[\"Item\", \"Element\"], value_vars=year_columns, \n",
    "                             var_name=\"Year\", value_name=\"Emissions\")\n",
    "\n",
    "    # Convert Year to integer and drop NaN values\n",
    "    df_ts[\"Year\"] = df_ts[\"Year\"].str[1:].astype(int)\n",
    "    df_ts = df_ts.dropna()\n",
    "\n",
    "    # Aggregate total emissions per year for each emission type\n",
    "    df_total = df_ts.groupby([\"Year\", \"Element\"])[\"Emissions\"].sum().unstack()\n",
    "\n",
    "    return df_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_emissions(df: pd.DataFrame, title: str):\n",
    "    \"\"\"\n",
    "    Plots historical emissions trends.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for col in df.columns:\n",
    "        plt.plot(df.index, df[col], marker='o', linestyle='-', label=col)\n",
    "    \n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Emissions (kt)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_emissions(df: pd.DataFrame, forecast_years=5, model_type=\"ARIMA\"):\n",
    "\n",
    "    forecast_years = forecast_years + 5\n",
    "\n",
    "    forecast_results = {\"Year\": list(range(df.index[-1] + 1, df.index[-1] + forecast_years + 1))}\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    df[\"Year\"] = pd.to_datetime(df[\"Year\"], format=\"%Y\")\n",
    "    df.set_index(\"Year\", inplace=True)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if model_type == \"ARIMA\":\n",
    "            model = ARIMA(df[col], order=(3, 1, 3)).fit()\n",
    "            forecast_results[col] = model.forecast(steps=forecast_years).values\n",
    "\n",
    "        elif model_type == \"SARIMA\":\n",
    "            model = SARIMAX(df[col], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12)).fit()\n",
    "            forecast_results[col] = model.forecast(steps=forecast_years).values\n",
    "\n",
    "        elif model_type == \"ETS\":\n",
    "            model = ExponentialSmoothing(df[col], trend=\"add\", seasonal=\"add\", seasonal_periods=12).fit()\n",
    "            forecast_results[col] = model.forecast(forecast_years)\n",
    "\n",
    "        elif model_type == \"HMM\":\n",
    "            series = df[col].values.reshape(-1, 1)\n",
    "\n",
    "            # Standardize the data\n",
    "            scaler = StandardScaler()\n",
    "            series_scaled = scaler.fit_transform(series)\n",
    "\n",
    "            # Fit Gaussian HMM\n",
    "            model = GaussianHMM(n_components=4, covariance_type=\"diag\", n_iter=1000)\n",
    "            model.fit(series_scaled)\n",
    "\n",
    "            # Start from the last observed value\n",
    "            last_state = model.predict(series_scaled)[-1]\n",
    "            current_state = last_state\n",
    "\n",
    "            # Use model's means and transition probabilities to simulate future\n",
    "            forecast_scaled = []\n",
    "            for _ in range(forecast_years):\n",
    "                next_state = np.random.choice(\n",
    "                    range(model.n_components), p=model.transmat_[current_state]\n",
    "                )\n",
    "                next_mean = model.means_[next_state][0]\n",
    "                forecast_scaled.append([next_mean])\n",
    "                current_state = next_state\n",
    "\n",
    "            # Inverse transform to get back to original scale\n",
    "            forecast_values = scaler.inverse_transform(forecast_scaled).flatten()\n",
    "            forecast_results[col] = forecast_values\n",
    "\n",
    "        elif model_type == \"LSTM\":\n",
    "            series = df[col].values.reshape(-1, 1)\n",
    "\n",
    "            # Scale data\n",
    "            scaler = MinMaxScaler()\n",
    "            series_scaled = scaler.fit_transform(series)\n",
    "\n",
    "            # Create sequences for LSTM (e.g., look back 5 years)\n",
    "            look_back = 5\n",
    "            X, y = [], []\n",
    "            for i in range(len(series_scaled) - look_back):\n",
    "                X.append(series_scaled[i:i+look_back])\n",
    "                y.append(series_scaled[i+look_back])\n",
    "            X, y = np.array(X), np.array(y)\n",
    "\n",
    "            # Define LSTM model\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(50, activation='relu', input_shape=(look_back, 1)))\n",
    "            model.add(Dense(1))\n",
    "            model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "            model.fit(X, y, epochs=200, verbose=0)\n",
    "\n",
    "            # Forecast future values\n",
    "            forecast_input = series_scaled[-look_back:].reshape(1, look_back, 1)\n",
    "            forecasted = []\n",
    "            for _ in range(forecast_years):\n",
    "                pred = model.predict(forecast_input)[0][0]\n",
    "                forecasted.append(pred)\n",
    "                forecast_input = np.append(forecast_input[:, 1:, :], [[[pred]]], axis=1)\n",
    "\n",
    "            forecasted_inverse = scaler.inverse_transform(np.array(forecasted).reshape(-1, 1)).flatten()\n",
    "            forecast_results[col] = forecasted_inverse\n",
    "\n",
    "        elif model_type == \"XGBoost\":\n",
    "            series = df[col].copy()\n",
    "            \n",
    "            # Create lag features\n",
    "            lag = 5\n",
    "            data = pd.DataFrame({f\"lag_{i}\": series.shift(i) for i in range(1, lag + 1)})\n",
    "            data[\"target\"] = series\n",
    "            data = data.dropna()\n",
    "\n",
    "            X = data.drop(columns=\"target\").values\n",
    "            y = data[\"target\"].values\n",
    "\n",
    "            # Scale features (optional but helpful for consistency)\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "            # Train XGBoost Regressor\n",
    "            model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1)\n",
    "            model.fit(X_scaled, y)\n",
    "\n",
    "            # Forecast into the future\n",
    "            last_values = series[-lag:].values.tolist()\n",
    "            forecast = []\n",
    "            for _ in range(forecast_years):\n",
    "                input_vals = np.array(last_values[-lag:]).reshape(1, -1)\n",
    "                input_scaled = scaler.transform(input_vals)\n",
    "                next_pred = model.predict(input_scaled)[0]\n",
    "                forecast.append(next_pred)\n",
    "                last_values.append(next_pred)\n",
    "\n",
    "            forecast_results[col] = forecast\n",
    "\n",
    "        elif model_type == \"RF\":\n",
    "            series = df[col].copy()\n",
    "\n",
    "            # Create lag features\n",
    "            lag = 5\n",
    "            data = pd.DataFrame({f\"lag_{i}\": series.shift(i) for i in range(1, lag + 1)})\n",
    "            data[\"target\"] = series\n",
    "            data = data.dropna()\n",
    "\n",
    "            X = data.drop(columns=\"target\").values\n",
    "            y = data[\"target\"].values\n",
    "\n",
    "            # Optional: scale inputs\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "            # Train Random Forest\n",
    "            model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "            model.fit(X_scaled, y)\n",
    "\n",
    "            # Forecasting\n",
    "            last_values = series[-lag:].values.tolist()\n",
    "            forecast = []\n",
    "            for _ in range(forecast_years):\n",
    "                input_vals = np.array(last_values[-lag:]).reshape(1, -1)\n",
    "                input_scaled = scaler.transform(input_vals)\n",
    "                next_pred = model.predict(input_scaled)[0]\n",
    "                forecast.append(next_pred)\n",
    "                last_values.append(next_pred)\n",
    "\n",
    "            forecast_results[col] = forecast\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model type. Choose from: ARIMA, SARIMA, ETS, XGBoost, LSTM, RF, HMM\")\n",
    "\n",
    "    return pd.DataFrame(forecast_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(df_historical: pd.DataFrame, df_forecast: pd.DataFrame, title: str) -> None:\n",
    "    \"\"\"\n",
    "    Plots historical data with forecasted trends.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Plot historical data\n",
    "    for col in df_historical.columns:\n",
    "        plt.plot(df_historical.index, df_historical[col], marker='o', linestyle='-', label=f\"Historical {col}\")\n",
    "    \n",
    "    # Plot forecast data\n",
    "    for col in df_forecast.columns[1:]:\n",
    "        plt.plot(df_forecast[\"Year\"], df_forecast[col], marker='s', linestyle='--', label=f\"Forecasted {col}\")\n",
    "\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Emissions (kt)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Turn off scientific notation\n",
    "    plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "    # Optional: Zoom in y-axis a little\n",
    "    all_values = np.concatenate([df_historical.values.flatten(), df_forecast.iloc[:, 1:].values.flatten()])\n",
    "    plt.ylim(all_values.min() * 0.95, all_values.max() * 1.05)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "### **1. Long-Term Growth (1961–2004):**\n",
    "- There is a clear upward trend in N₂O emissions from 1961 through the early 2000s.\n",
    "- Emissions gradually increased from around 1 kt in 1961 to over 20 kt by the early 2000s, with more rapid increases starting in the 1980s.\n",
    "\n",
    "### **2. Sharp Increase (2004–2006):**\n",
    "- Around 2004–2005, emissions experienced a very sharp spike, rising from about 21 kt to over 40 kt in a very short period.\n",
    "\n",
    "### **3. Peak and Fluctuation (2006–2012):**\n",
    "- Emissions peaked around 2008 at approximately 45 kt.\n",
    "- From 2006 to 2012, emissions fluctuated significantly, staying mostly above 40 kt but showing year-to-year variability.\n",
    "\n",
    "### **4. Sharp Drop and Recovery (Post-2012):**\n",
    "- After 2012, there was a sharp drop in emissions, falling to below 25 kt.\n",
    "- Since then, emissions have shown some recovery and fluctuation, with an upward trend toward 2021, reaching above 30 kt again.\n",
    "\n",
    "### **5. No Clear Seasonal Pattern:**\n",
    "- The data appears to be annual, not monthly or quarterly, so no seasonal (within-year) pattern is discernible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = \"Bangladesh\"\n",
    "items = [5061]  # Synthetic Fertilizers\n",
    "elements = [\"Emissions (N2O)\"]\n",
    "\n",
    "df_cleaned = preprocess_emissions_data(df, [area], items, elements)\n",
    "\n",
    "df_before_2025 = df_cleaned[df_cleaned.index < 2022]\n",
    "\n",
    "df_trimmed = df_before_2025.iloc[:-5]\n",
    "\n",
    "plot_emissions(df_before_2025, f\"Historical N2O Emissions from Synthetic Fertilizers in {area}\")\n",
    "\n",
    "df_forecasted = forecast_emissions(df_trimmed, forecast_years=10, model_type='ETS')\n",
    "\n",
    "plot_forecast(df_before_2025, df_forecasted, f\"Forecasted N2O Emissions in {area} (Synthetic Fertilizers)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "### **N₂O Emissions:**\n",
    "- ***From Drained Organic Soils (Item: 67291):***\n",
    "    - Emissions were relatively stable at ~0.23 kt/year from 1990–1997.\n",
    "    - There was a gradual increase from ~0.23 kt in 1998 to ~0.27 kt by the mid-2000s.\n",
    "    - Post-2005, emissions stabilized around 0.27–0.273 kt/year through 2022.\n",
    "\n",
    "- ***From Savanna Fires (Item: 6795):***\n",
    "    - Range from ~10 kt/year to ~56 kt/year.\n",
    "    - Emissions fluctuate year-to-year, with notable increases around 2010.\n",
    "\n",
    "### **CH₄ Emissions:**\n",
    "- ***From Savanna Fires (Item: 6795):***\n",
    "    - From ~60 kt/year to over 620 kt/year, with major peaks around 2011 and 2021.\n",
    "\n",
    "**Total Overall Emissions for N₂O is around 24kt and for CH₄ is around 260kt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = \"Southern Africa\"\n",
    "items = [67291]  # Drained Organic Soils\n",
    "elements = [\"Emissions (N2O)\", \"Emissions (CH4)\"]\n",
    "\n",
    "df_cleaned = preprocess_emissions_data(df, [area], items, elements)\n",
    "\n",
    "df_trimmed = df_cleaned.iloc[:-5]\n",
    "\n",
    "plot_emissions(df_cleaned, f\"Total Historical N2O & CH4 Emissions in {area}\")\n",
    "\n",
    "df_forecasted = forecast_emissions(df_trimmed, forecast_years=5, model_type='ETS')\n",
    "\n",
    "plot_forecast(df_cleaned, df_forecasted, f\"Forecasted Emissions in {area}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = \"Southern Africa\"\n",
    "items = [6795]  # Savanna Fires\n",
    "elements = [\"Emissions (N2O)\", \"Emissions (CH4)\"]\n",
    "\n",
    "df_cleaned = preprocess_emissions_data(df, [area], items, elements)\n",
    "\n",
    "df_trimmed = df_cleaned.iloc[:-5]\n",
    "\n",
    "plot_emissions(df_cleaned, f\"Total Historical N2O & CH4 Emissions in {area}\")\n",
    "\n",
    "df_forecasted = forecast_emissions(df_trimmed, forecast_years=5, model_type='XGBoost')\n",
    "\n",
    "plot_forecast(df_cleaned, df_forecasted, f\"Forecasted Emissions in {area}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "- Emissions efficiency was calculated using relative N₂O emissions (CO₂eq) from agricultural land due to lack of economic data.\n",
    "- Forecasts predict Uganda’s emissions will increase steadily over the next decade.\n",
    "- Benin is expected to maintain or slightly increase emissions over the next decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = [\"Uganda\"]\n",
    "item = [6995]\n",
    "element = [\"Emissions (CO2eq) from N2O (AR5)\"]\n",
    "\n",
    "df_uganda = preprocess_emissions_data(df, area, item, element)\n",
    "df_benin = preprocess_emissions_data(df, [\"Benin\"], item, element)\n",
    "df_uganda = df_uganda.reset_index()\n",
    "df_uganda.rename(columns={'Emissions (CO2eq) from N2O (AR5)': 'Uganda'}, inplace=True)\n",
    "df_benin = df_benin.reset_index()\n",
    "df_benin.rename(columns={'Emissions (CO2eq) from N2O (AR5)': 'Benin'}, inplace=True)\n",
    "\n",
    "df_eff = pd.merge(df_uganda, df_benin, on='Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate relative efficiency\n",
    "df_eff['RE_Uganda'] = df_eff['Uganda'] / df_eff['Uganda'].shift(1)\n",
    "df_eff['RE_Benin'] = df_eff['Benin'] / df_eff['Benin'].shift(1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_eff['Year'], df_eff['RE_Uganda'], marker='o', linestyle='-', label='Relative Efficiency Uganda')\n",
    "plt.plot(df_eff['Year'], df_eff['RE_Benin'], marker='o', linestyle='-', label='Relative Efficiency Benin')\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Relative Efficiency in %\")\n",
    "plt.title('Relative Efficiency')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = \"Uganda\"\n",
    "item = 6995  # Agricultural Land\n",
    "element = \"Emissions (CO2eq) from N2O (AR5)\"\n",
    "\n",
    "df_cleaned = preprocess_emissions_data(df, [area], [item], [element])\n",
    "\n",
    "df_trimmed = df_cleaned.iloc[:-5]\n",
    "\n",
    "plot_emissions(df_cleaned, \"Historical CO2eq Emissions Efficiency from Agricultural Land\")\n",
    "\n",
    "df_forecasted = forecast_emissions(df_trimmed, forecast_years=10, model_type='SARIMA')\n",
    "\n",
    "plot_forecast(df_cleaned, df_forecasted, f\"Forecasted Emissions in {area}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = \"Benin\"\n",
    "item = 6995  # Agricultural Land\n",
    "element = \"Emissions (CO2eq) from N2O (AR5)\"\n",
    "\n",
    "df_cleaned = preprocess_emissions_data(df, [area], [item], [element])\n",
    "\n",
    "df_trimmed = df_cleaned.iloc[:-5]\n",
    "\n",
    "plot_emissions(df_cleaned, \"Historical CO2eq Emissions Efficiency from Agricultural Land\")\n",
    "\n",
    "df_forecasted = forecast_emissions(df_trimmed, forecast_years=10, model_type='SARIMA')\n",
    " \n",
    "plot_forecast(df_cleaned, df_forecasted, f\"Forecasted Emissions in {area}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Required data for sudan is low in count and as a result the the forecast struggles to accurately forecast the emission\n",
    "From the available data we can arrive that the trends are uniformly linear in both cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = \"Sudan\"\n",
    "item = 6818  # Waste-related\n",
    "element = \"Emissions (CO2eq) from CH4 (AR5)\"\n",
    "\n",
    "df_cleaned = preprocess_emissions_data(df, [area], [item], [element])\n",
    "\n",
    "df_trimmed = df_cleaned.iloc[:-5]\n",
    "\n",
    "plot_emissions(df_cleaned, \"Waste-Related CO2eq Emissions from CH4\")\n",
    "\n",
    "df_forecasted = forecast_emissions(df_trimmed, forecast_years=10, model_type='ARIMA')\n",
    "\n",
    "plot_forecast(df_cleaned, df_forecasted, f\"Forecasted Emissions in {area}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = \"Non-Annex I countries\"\n",
    "item = 6818  # Waste-related\n",
    "element = \"Emissions (CO2eq) from CH4 (AR5)\"\n",
    "\n",
    "df_cleaned = preprocess_emissions_data(df, [area], [item], [element])\n",
    "\n",
    "df_trimmed = df_cleaned.iloc[:-5]\n",
    "\n",
    "plot_emissions(df_cleaned, \"Waste-Related CO2eq Emissions from CH4\")\n",
    "\n",
    "df_forecasted = forecast_emissions(df_trimmed, forecast_years=10, model_type='ARIMA')\n",
    "\n",
    "plot_forecast(df_cleaned, df_forecasted, f\"Forecasted Emissions in {area}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "The data is either empty or constant for these entries and hence no time series forecasting can be done.\n",
    "since the data is empty in one and possibly wrong in the other it is not possible to forecast their emmissions for the next 10 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = [\"Malawi\"]\n",
    "item = 6750  # Net Forest Conversion\n",
    "element = \"Emissions (CO2eq) (AR5)\"\n",
    "\n",
    "df_cleaned = preprocess_emissions_data(df, areas, [item], [element])\n",
    "\n",
    "plot_emissions(df_cleaned, \"CO2eq Emissions from Net Forest Conversion\")\n",
    "\n",
    "df_forecasted = forecast_emissions(df_cleaned, forecast_years=10, model_type='RF')\n",
    "\n",
    "plot_forecast(df_cleaned, df_forecasted, \"Forecasted CO2eq Emissions in Malawi & Afghanistan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = [\"Afghanistan\"]\n",
    "item = 6750  # Net Forest Conversion\n",
    "element = \"Emissions (CO2eq) (AR5)\"\n",
    "\n",
    "df_cleaned = preprocess_emissions_data(df, areas, [item], [element])\n",
    "\n",
    "plot_emissions(df_cleaned, \"CO2eq Emissions from Net Forest Conversion\")\n",
    "\n",
    "df_forecasted = forecast_emissions(df_cleaned, forecast_years=10, model_type='RF')\n",
    "\n",
    "plot_forecast(df_cleaned, df_forecasted, \"Forecasted CO2eq Emissions in Malawi & Afghanistan\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = \"Benin\"\n",
    "item = 6995  # Agricultural Land\n",
    "element = \"Emissions (CO2eq) from N2O (AR5)\"\n",
    "\n",
    "df_cleaned = preprocess_emissions_data(df, [area], [item], [element])\n",
    "\n",
    "df_before_2025 = df_cleaned[df_cleaned.index < 2022]\n",
    "\n",
    "# Example: Focus on just N2O\n",
    "n2o_series = df_before_2025[element]\n",
    "\n",
    "analyze_timeseries(n2o_series, title=f'{element} Emissions Analysis')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
